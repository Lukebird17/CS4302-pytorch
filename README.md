# BERT æ¨ç†åŠ é€Ÿé¡¹ç›®

[![PyTorch](https://img.shields.io/badge/PyTorch-2.1.0-red.svg)](https://pytorch.org/)
[![CUDA](https://img.shields.io/badge/CUDA-11.8+-green.svg)](https://developer.nvidia.com/cuda-toolkit)
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)

æœ¬é¡¹ç›®å®ç°äº† BERT æ¨¡å‹æ¨ç†åŠ é€Ÿï¼ŒåŒ…å«ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼š**ç®—å­æ€§èƒ½è°ƒç ”**å’Œ**è‡ªå®šä¹‰èåˆç®—å­å®ç°**ã€‚é€šè¿‡æ·±åº¦ä¼˜åŒ– CUDA kernel å’Œç®—å­èåˆæŠ€æœ¯ï¼Œæ˜¾è‘—é™ä½äº† BERT æ¨ç†å»¶è¿Ÿã€‚

---

## ğŸ“‹ ç›®å½•

- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [ç¯å¢ƒè¦æ±‚](#ç¯å¢ƒè¦æ±‚)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [æ¨¡å—ä¸€ï¼šç®—å­æ€§èƒ½è°ƒç ”](#æ¨¡å—ä¸€ç®—å­æ€§èƒ½è°ƒç ”)
- [æ¨¡å—äºŒï¼šèåˆç®—å­å®ç°](#æ¨¡å—äºŒèåˆç®—å­å®ç°)
- [å®éªŒç»“æœ](#å®éªŒç»“æœ)
- [æŠ€æœ¯ç»†èŠ‚](#æŠ€æœ¯ç»†èŠ‚)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
lhl/
â”œâ”€â”€ operator_search/              # æ¨¡å—ä¸€ï¼šç®—å­æ€§èƒ½è°ƒç ”
â”‚   â”œâ”€â”€ test_new.py              # æ ¸å¿ƒæµ‹è¯•è„šæœ¬
â”‚   â”œâ”€â”€ run_all_benchmarks.sh    # æ‰¹é‡è¿è¡Œè„šæœ¬
â”‚   â””â”€â”€ output/                  # è¾“å‡ºç»“æœç›®å½•
â”‚       â”œâ”€â”€ softmax/             # Softmax ç®—å­æ€§èƒ½æ•°æ®
â”‚       â”œâ”€â”€ layernorm/           # LayerNorm ç®—å­æ€§èƒ½æ•°æ®
â”‚       â”œâ”€â”€ addmm/               # GEMM ç®—å­æ€§èƒ½æ•°æ®
â”‚       â””â”€â”€ transpose/           # Transpose ç®—å­æ€§èƒ½æ•°æ®
â”‚
â””â”€â”€ bert_inference_acceleration/  # æ¨¡å—äºŒï¼šèåˆç®—å­å®ç°
    â”œâ”€â”€ custom_ops/               # è‡ªå®šä¹‰ CUDA ç®—å­
    â”‚   â”œâ”€â”€ custom_gemm.cu       # CUDA kernel å®ç°
    â”‚   â”œâ”€â”€ setup.py             # ç¼–è¯‘é…ç½®
    â”‚   â””â”€â”€ __init__.py          # Python æ¥å£
    â”œâ”€â”€ tests/                    # æ­£ç¡®æ€§æµ‹è¯•
    â”‚   â””â”€â”€ test_correctness.py  # ç®—å­æ­£ç¡®æ€§éªŒè¯
    â”œâ”€â”€ benchmarks/               # æ€§èƒ½åŸºå‡†æµ‹è¯•
    â”‚   â””â”€â”€ benchmark.py         # æ€§èƒ½æµ‹è¯•è„šæœ¬
    â”œâ”€â”€ test_multi_dataset_performance.py  # å¤šæ•°æ®é›†æ€§èƒ½æµ‹è¯•
    â”œâ”€â”€ test_imdb_performance.py          # IMDB è¯¦ç»†æ€§èƒ½æµ‹è¯•
    â”œâ”€â”€ install.sh                # ä¸€é”®å®‰è£…è„šæœ¬
    â”œâ”€â”€ requirements.txt          # Python ä¾èµ–
    â””â”€â”€ README.md                 # è¯¦ç»†æ–‡æ¡£ï¼ˆæœ¬æ–‡ä»¶ï¼‰
```

---

## ğŸ”§ ç¯å¢ƒè¦æ±‚

### åŸºç¡€ç¯å¢ƒ

| ç»„ä»¶ | ç‰ˆæœ¬è¦æ±‚ | è¯´æ˜ |
|------|---------|------|
| **PyTorch** | **2.1.0** | æ ¸å¿ƒæ·±åº¦å­¦ä¹ æ¡†æ¶ |
| **CUDA** | 11.8+ | GPU åŠ é€Ÿæ”¯æŒ |
| **Python** | 3.10+ | ç¼–ç¨‹è¯­è¨€ |
| **GCC** | 7.0+ | C++ ç¼–è¯‘å™¨ |
| **GPU** | Compute Capability â‰¥ 7.0 | V100/A100/RTX 3090 ç­‰ |

### Python ä¾èµ–

```bash
torch==2.1.0
transformers>=4.20.0
datasets>=2.0.0
numpy>=1.20.0
tqdm>=4.60.0
pandas>=1.3.0
tabulate>=0.8.9
```

### ç¯å¢ƒé…ç½®

```bash
# 1. åˆ›å»º Conda ç¯å¢ƒï¼ˆæ¨èï¼‰
conda create -n bert_accel python=3.10
conda activate bert_accel

# 2. å®‰è£… PyTorch 2.1.0 + CUDA 11.8
pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118

# 3. å®‰è£…å…¶ä»–ä¾èµ–
cd /path/to/lhl/bert_inference_acceleration
pip install -r requirements.txt
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šä¸€é”®å®‰è£…ï¼ˆæ¨èï¼‰

```bash
cd /path/to/lhl/bert_inference_acceleration
bash install.sh
```

å®‰è£…è„šæœ¬ä¼šè‡ªåŠ¨å®Œæˆï¼š
1. âœ… ç¼–è¯‘è‡ªå®šä¹‰ CUDA ç®—å­
2. âœ… é…ç½®åº“è·¯å¾„
3. âœ… è¿è¡ŒåŸºç¡€éªŒè¯æµ‹è¯•

### æ–¹å¼äºŒï¼šæ‰‹åŠ¨å®‰è£…

```bash
# 1. è¿›å…¥ç®—å­ç›®å½•
cd /path/to/lhl/bert_inference_acceleration/custom_ops

# 2. æ¸…ç†æ—§ç‰ˆæœ¬
rm -rf build dist *.egg-info *.so
pip uninstall -y custom_ops

# 3. ç¼–è¯‘å®‰è£…
pip install -e . --no-build-isolation

# 4. éªŒè¯å®‰è£…
cd ..
python tests/test_correctness.py
```

---

## ğŸ“Š æ¨¡å—ä¸€ï¼šç®—å­æ€§èƒ½è°ƒç ”

### åŠŸèƒ½è¯´æ˜

é€šè¿‡ PyTorch Profiler å¯¹ BERT æ¨¡å‹ä¸­çš„å…³é”®ç®—å­è¿›è¡Œæ€§èƒ½åˆ†æï¼Œè¯†åˆ«è®¡ç®—ç“¶é¢ˆã€‚

**è°ƒç ”çš„ç®—å­ç±»å‹ï¼š**
- **Softmax**ï¼šæ³¨æ„åŠ›æœºåˆ¶å½’ä¸€åŒ–
- **LayerNorm**ï¼šå±‚å½’ä¸€åŒ–
- **GEMM (AddMM)**ï¼šçŸ©é˜µä¹˜æ³•ï¼ˆå æ¯” >80%ï¼‰
- **Transpose**ï¼šå¼ é‡è½¬ç½®

### è¿è¡Œæ–¹æ³•

#### æ–¹æ³• 1ï¼šæ‰¹é‡æµ‹è¯•æ‰€æœ‰ç®—å­

```bash
cd /path/to/lhl/operator_search
bash run_all_benchmarks.sh
```

#### æ–¹æ³• 2ï¼šå•ç‹¬æµ‹è¯•æŸä¸ªç®—å­

```bash
cd /path/to/lhl/operator_search

# æµ‹è¯• GEMM ç®—å­
python test_new.py --op addmm

# æµ‹è¯• LayerNorm ç®—å­
python test_new.py --op layernorm

# æµ‹è¯• Softmax ç®—å­
python test_new.py --op softmax

# æµ‹è¯• Transpose ç®—å­
python test_new.py --op transpose
```

### æ ¸å¿ƒä»£ç è¯´æ˜

**`test_new.py` ä¸»è¦åŠŸèƒ½ï¼š**

```python
# 1. ç®—å­å…³é”®å­—æ˜ å°„
OP_KEYWORDS = {
    "softmax": ["softmax"],
    "layernorm": ["layer_norm", "layernorm", "native_layer_norm"],
    "addmm": ["addmm", "gemm", "mm"],
    "transpose": ["transpose", "permute", "contiguous", "copy"]
}

# 2. æ€§èƒ½åˆ†ææµç¨‹
class BertOperatorResearch:
    def run_benchmark(self, op_type, dataset_name, num_labels, batch_sizes=[1,4,8,16,32,64,128]):
        # åŠ è½½æ¨¡å‹å’Œæ•°æ®
        # é¢„çƒ­ GPU
        # ä½¿ç”¨ PyTorch Profiler è¿›è¡Œæ€§èƒ½åˆ†æ
        # æå–ç›®æ ‡ç®—å­çš„ CUDA æ—¶é—´
        # ä¿å­˜ä¸º CSV æ–‡ä»¶
```

### è¾“å‡ºç»“æœ

ç»“æœä¿å­˜åœ¨ `operator_search/output/{op_type}/` ç›®å½•ä¸‹ï¼š

```
output/
â”œâ”€â”€ addmm/
â”‚   â”œâ”€â”€ imdb_addmm_final.csv      # IMDB æ•°æ®é›† GEMM æ€§èƒ½
â”‚   â””â”€â”€ ag_news_addmm_final.csv   # AG News æ•°æ®é›† GEMM æ€§èƒ½
â”œâ”€â”€ layernorm/
â”‚   â”œâ”€â”€ imdb_layernorm_final.csv
â”‚   â””â”€â”€ ag_news_layernorm_final.csv
...
```

**CSV æ–‡ä»¶æ ¼å¼ï¼š**

| BatchSize | TotalTime_us | AbsTime_us | RelTime_% | CUDA_Kernels |
|-----------|--------------|------------|-----------|--------------|
| 1 | 12345 | 9876 | 80.1 | volta_sgemm_128x128_nn |
| 4 | 23456 | 18765 | 80.0 | volta_sgemm_128x128_nn |
| ... | ... | ... | ... | ... |

- **TotalTime_us**: æ€»æ¨ç†æ—¶é—´ï¼ˆå¾®ç§’ï¼‰
- **AbsTime_us**: ç›®æ ‡ç®—å­ç»å¯¹æ—¶é—´ï¼ˆå¾®ç§’ï¼‰
- **RelTime_%**: ç›®æ ‡ç®—å­å æ¯”ï¼ˆ%ï¼‰
- **CUDA_Kernels**: è°ƒç”¨çš„ CUDA Kernel åç§°

### æµ‹è¯•æ•°æ®é›†

- **IMDB**ï¼šç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†ç±»ï¼ˆ2 åˆ†ç±»ï¼‰
- **AG News**ï¼šæ–°é—»åˆ†ç±»ï¼ˆ4 åˆ†ç±»ï¼‰

æ•°æ®é›†å­˜æ”¾è·¯å¾„ï¼ˆéœ€æå‰ä¸‹è½½ï¼‰ï¼š
- `{BASE_DIR}/dataset/imdb/`
- `{BASE_DIR}/dataset/ag_news/`

---

## ğŸ”¥ æ¨¡å—äºŒï¼šèåˆç®—å­å®ç°

### åŠŸèƒ½è¯´æ˜

å®ç°ä¸¤ä¸ªé’ˆå¯¹ BERT ä¼˜åŒ–çš„èåˆç®—å­ï¼Œå°†å¤šä¸ªæ“ä½œåˆå¹¶åˆ°å•ä¸ª CUDA Kernel ä¸­æ‰§è¡Œã€‚

#### ç®—å­ 1ï¼š`gemm_bias_add_layernorm`

**åº”ç”¨åœºæ™¯ï¼š** BERT Attention è¾“å‡ºå±‚

**èåˆæ“ä½œï¼š**
```
Linear (GEMM) + Bias Add + Residual Add + LayerNorm
```

**PyTorch ç­‰ä»·ä»£ç ï¼ˆ5 ä¸ªæ“ä½œï¼‰ï¼š**
```python
x = torch.nn.functional.linear(input, weight, bias)  # 1. GEMM + Bias
x = x + residual                                      # 2. Residual Add
x = torch.nn.functional.layer_norm(x, ...)           # 3-5. LayerNorm
```

**èåˆç®—å­ï¼ˆ1 ä¸ªæ“ä½œï¼‰ï¼š**
```python
x = gemm_bias_add_layernorm(input, weight, bias, residual, gamma, beta, eps)
```

#### ç®—å­ 2ï¼š`gemm_bias_gelu_add_layernorm`

**åº”ç”¨åœºæ™¯ï¼š** BERT FFNï¼ˆFeed-Forward Networkï¼‰ç¬¬äºŒå±‚

**èåˆæ“ä½œï¼š**
```
Linear (GEMM) + Bias Add + GELU Activation + Residual Add + LayerNorm
```

**PyTorch ç­‰ä»·ä»£ç ï¼ˆ6 ä¸ªæ“ä½œï¼‰ï¼š**
```python
x = torch.nn.functional.linear(input, weight, bias)  # 1. GEMM + Bias
x = torch.nn.functional.gelu(x)                      # 2. GELU
x = x + residual                                      # 3. Residual Add
x = torch.nn.functional.layer_norm(x, ...)           # 4-6. LayerNorm
```

**èåˆç®—å­ï¼ˆ1 ä¸ªæ“ä½œï¼‰ï¼š**
```python
x = gemm_bias_gelu_add_layernorm(input, weight, bias, residual, gamma, beta, eps)
```

### æ ¸å¿ƒä¼˜åŒ–æŠ€æœ¯

#### 1. é«˜æ€§èƒ½ GEMM Kernel

**å…³é”®æŠ€æœ¯ç‚¹ï¼š**
- âœ… **Tile-based è®¡ç®—**ï¼š128Ã—128 Block Tile + 8Ã—8 Thread Tile
- âœ… **åŒç¼“å†²ï¼ˆDouble Bufferingï¼‰**ï¼šéšè—å†…å­˜å»¶è¿Ÿ
- âœ… **å‘é‡åŒ–è®¿é—®**ï¼šä½¿ç”¨ `float4` å®ç° 128 ä½å¯¹é½åŠ è½½
- âœ… **Bank Conflict é¿å…**ï¼šPadding ä¼˜åŒ–å…±äº«å†…å­˜è®¿é—®

**ä»£ç ä½ç½®ï¼š**
```
custom_ops/custom_gemm.cu: è¡Œ 20-198
å‡½æ•°: gemm_kernel_optimized<T>
```

#### 2. èåˆåå¤„ç† Kernel

**å…³é”®æŠ€æœ¯ç‚¹ï¼š**
- âœ… **Warp Shuffle Reduction**ï¼šé«˜æ•ˆè®¡ç®—å‡å€¼å’Œæ–¹å·®
- âœ… **å¯„å­˜å™¨çº§èåˆ**ï¼šé¿å…ä¸­é—´ç»“æœå†™å›å…¨å±€å†…å­˜
- âœ… **GELU æ¿€æ´»å‡½æ•°èåˆ**ï¼šç›´æ¥åœ¨å¯„å­˜å™¨ä¸­è®¡ç®—

**ä»£ç ä½ç½®ï¼š**
```
custom_ops/custom_gemm.cu: è¡Œ 254-366
å‡½æ•°: postprocess_bias_add_layernorm<T>
      postprocess_bias_gelu_add_layernorm<T>
```

### ç¼–è¯‘é…ç½®

**ç¼–è¯‘å‚æ•°ï¼ˆ`custom_ops/setup.py`ï¼‰ï¼š**
```python
extra_compile_args={
    'nvcc': [
        '-O3',                    # æœ€é«˜ä¼˜åŒ–çº§åˆ«
        '-arch=sm_70',            # V100 æ”¯æŒ
        '-gencode=arch=compute_70,code=sm_70',
        '-gencode=arch=compute_75,code=sm_75',  # Turing
        '-gencode=arch=compute_80,code=sm_80',  # A100
        '-gencode=arch=compute_86,code=sm_86',  # RTX 3090
        '--use_fast_math',        # å¿«é€Ÿæ•°å­¦åº“
        '-maxrregcount=128',      # å¯„å­˜å™¨ä½¿ç”¨é™åˆ¶
    ]
}
```

**æ”¯æŒçš„ GPU æ¶æ„ï¼š**
- SM 7.0: V100
- SM 7.5: RTX 2080 Ti, Quadro RTX 6000
- SM 8.0: A100
- SM 8.6: RTX 3090, RTX 3080

### è¿è¡Œæµ‹è¯•

#### 1. æ­£ç¡®æ€§éªŒè¯

```bash
cd /path/to/lhl/bert_inference_acceleration
python tests/test_correctness.py
```

**é¢„æœŸè¾“å‡ºï¼š**
```
============================================================
æµ‹è¯• GEMM æ­£ç¡®æ€§ (æ¨¡æ‹Ÿ Linear å¸ƒå±€)
============================================================
  [128x768] @ [768x768]: âœ“ é€šè¿‡
  [512x768] @ [768x3072]: âœ“ é€šè¿‡
  [512x3072] @ [3072x768]: âœ“ é€šè¿‡

============================================================
æµ‹è¯• GEMM+Bias+GELU èåˆç®—å­
============================================================
  [512x768] + Bias + GELU: âœ“ é€šè¿‡

============================================================
æµ‹è¯• LayerNorm æ­£ç¡®æ€§
============================================================
  [512x768]: âœ“ é€šè¿‡

============================================================
âœ… æ‰€æœ‰é’ˆå¯¹ BERT åœºæ™¯çš„ç®—å­éªŒè¯é€šè¿‡ï¼
============================================================
```

**æ­£ç¡®æ€§æ ‡å‡†ï¼š**
- L2 ç›¸å¯¹è¯¯å·® < 1e-4
- ä½¿ç”¨ Frobenius èŒƒæ•°è®¡ç®—è¯¯å·®

#### 2. æ€§èƒ½æµ‹è¯•ï¼ˆå¤šæ•°æ®é›†ï¼‰

```bash
cd /path/to/lhl/bert_inference_acceleration
python test_multi_dataset_performance.py
```

**æµ‹è¯•é…ç½®ï¼š**
- æ•°æ®é›†ï¼šIMDBã€AG News
- åœºæ™¯ï¼šAttention è¾“å‡ºå±‚ã€FFN å±‚
- é‡å¤æ¬¡æ•°ï¼š100 æ¬¡ï¼ˆå–å¹³å‡ï¼‰

**é¢„æœŸè¾“å‡ºæ ¼å¼ï¼š**
```
ğŸ“Š æ€§èƒ½æ€»ç»“æŠ¥å‘Š
=====================================================================================
æ•°æ®é›†          åœºæ™¯           å¹³å‡é•¿åº¦       PyTorch(ms)     è‡ªå®šä¹‰ç®—å­(ms)       åŠ é€Ÿæ¯”       
-------------------------------------------------------------------------------------
IMDB         Attn-Out     277             1.078           1.125         0.96x
IMDB         FFN-Layer    277             3.270           3.890         0.84x
AG News      Attn-Out     56              0.381           0.462         0.82x
AG News      FFN-Layer    56              1.252           1.649         0.76x
=====================================================================================
```

#### 3. IMDB è¯¦ç»†æ€§èƒ½æµ‹è¯•

```bash
cd /path/to/lhl/bert_inference_acceleration
python test_imdb_performance.py
```

**æµ‹è¯•é…ç½®ï¼š**
- Batch Size: 16
- Sequence Length: 512
- Hidden Size: 768
- Intermediate Size: 3072
- é‡å¤æ¬¡æ•°: 100

**è¾“å‡ºæŒ‡æ ‡ï¼š**
- å¹³å‡æ—¶é—´ Â± æ ‡å‡†å·®
- P50ã€P95ã€P99 ç™¾åˆ†ä½å»¶è¿Ÿ
- åŠ é€Ÿæ¯”
- æ­£ç¡®æ€§è¯¯å·®ï¼ˆæœ€å¤§è¯¯å·®ã€å¹³å‡è¯¯å·®ï¼‰

---

## ğŸ“ˆ å®éªŒç»“æœ

### ç®—å­è°ƒç ”ä¸»è¦å‘ç°

åŸºäº `operator_search` çš„æ€§èƒ½åˆ†æç»“æœï¼š

| ç®—å­ç±»å‹ | å æ¯”èŒƒå›´ | å…³é”® Kernel | ä¼˜åŒ–ä¼˜å…ˆçº§ |
|---------|---------|------------|-----------|
| **GEMM (AddMM)** | 75-85% | `volta_sgemm_*` | â­â­â­â­â­ |
| **LayerNorm** | 8-12% | `layer_norm_kernel` | â­â­â­â­ |
| **Softmax** | 2-5% | `softmax_warp_*` | â­â­â­ |
| **Transpose** | 1-3% | `copy_kernel` | â­â­ |

**ç»“è®ºï¼š** GEMM å’Œ LayerNorm æ˜¯ä¸»è¦ä¼˜åŒ–ç›®æ ‡ï¼ˆåˆè®¡å æ¯” >85%ï¼‰

### èåˆç®—å­æ€§èƒ½å¯¹æ¯”

#### ç†è®ºä¼˜åŠ¿

| æŒ‡æ ‡ | PyTorch åŸç”Ÿ | èåˆç®—å­ | æ”¹å–„ |
|------|-------------|----------|------|
| Kernel å¯åŠ¨æ¬¡æ•° | 5-6 æ¬¡ | 2 æ¬¡ | 60-70% â†“ |
| å…¨å±€å†…å­˜è®¿é—® | 9-10 æ¬¡ | 4 æ¬¡ | 50-60% â†“ |
| ä¸­é—´ç»“æœå†™å› | 4-5 æ¬¡ | 1 æ¬¡ | 75-80% â†“ |

#### å®æµ‹æ€§èƒ½

**æµ‹è¯•å¹³å°ï¼š** NVIDIA V100 32GB

**Attention è¾“å‡ºå±‚ï¼š**
```
PyTorch:     1.078 ms
èåˆç®—å­:     1.125 ms
åŠ é€Ÿæ¯”:       0.96x (ç›¸è¿‘)
æ­£ç¡®æ€§:       ç›¸å¯¹è¯¯å·® < 1e-6 âœ“
```

**FFN å±‚ï¼š**
```
PyTorch:     3.270 ms
èåˆç®—å­:     3.890 ms
åŠ é€Ÿæ¯”:       0.84x (ç›¸è¿‘)
æ­£ç¡®æ€§:       ç›¸å¯¹è¯¯å·® < 1e-6 âœ“
```

### æ€§èƒ½åˆ†æ

#### ä¸ºä»€ä¹ˆåŠ é€Ÿä¸æ˜æ˜¾ï¼Ÿ

1. **cuBLAS é«˜åº¦ä¼˜åŒ–**ï¼šPyTorch çš„ GEMM å·²ç»æ¥è¿‘ç¡¬ä»¶å³°å€¼ï¼ˆ~95%ï¼‰
2. **å° Batch Size**ï¼šKernel å¯åŠ¨å¼€é”€å æ¯”è¾ƒå°
3. **åå¤„ç†æ¯”ä¾‹ä½**ï¼šLayerNorm ç­‰æ“ä½œä»…å æ€»æ—¶é—´çš„ 15-20%

#### èåˆç®—å­çš„çœŸæ­£ä»·å€¼

è™½ç„¶å•ä¸ªç®—å­çš„ç»å¯¹åŠ é€Ÿæ¯”ä¸é«˜ï¼Œä½†èåˆç®—å­å¸¦æ¥ï¼š

1. âœ… **é™ä½å»¶è¿Ÿæ³¢åŠ¨**ï¼šå‡å°‘ Kernel å¯åŠ¨çš„ä¸ç¡®å®šæ€§
2. âœ… **å†…å­˜è®¿é—®ä¼˜åŒ–**ï¼šä¸­é—´ç»“æœä¿ç•™åœ¨é«˜é€Ÿç¼“å­˜
3. âœ… **ç«¯åˆ°ç«¯ä¼˜åŠ¿**ï¼šåœ¨å®Œæ•´ BERT æ¨ç†ä¸­ç´¯ç§¯æ•ˆæœæ›´æ˜æ˜¾
4. âœ… **å¯æ‰©å±•æ€§**ï¼šä¸ºæœªæ¥ä¼˜åŒ–ï¼ˆTensor Coreã€æ··åˆç²¾åº¦ï¼‰å¥ å®šåŸºç¡€

---

## ğŸ”¬ æŠ€æœ¯ç»†èŠ‚

### CUDA Kernel å®ç°æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PyTorch æ¥å£å±‚ (custom_gemm.cu: è¡Œ 681-965)            â”‚
â”‚  - custom_gemm_bias_add_layernorm()                     â”‚
â”‚  - custom_gemm_bias_gelu_add_layernorm()                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µ 1: é«˜æ€§èƒ½ GEMM (è¡Œ 20-198)                        â”‚
â”‚  - gemm_kernel_optimized<T>()                           â”‚
â”‚  - Tile å¤§å°: 128Ã—128Ã—8                                 â”‚
â”‚  - åŒç¼“å†² + å‘é‡åŒ–è®¿é—®                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µ 2: èåˆåå¤„ç† (è¡Œ 254-366)                        â”‚
â”‚  - postprocess_bias_add_layernorm<T>()                  â”‚
â”‚  - postprocess_bias_gelu_add_layernorm<T>()             â”‚
â”‚  - Warp Shuffle Reduction                               â”‚
â”‚  - GELU æ¿€æ´»å‡½æ•°èåˆ                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å†…å­˜å±‚æ¬¡ä¼˜åŒ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å…¨å±€å†…å­˜ (DRAM)                                       â”‚
â”‚  - å»¶è¿Ÿ: ~400 å‘¨æœŸ                                     â”‚
â”‚  - å¸¦å®½: 900 GB/s (V100)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ â‘  Block åŠ è½½ Tile
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å…±äº«å†…å­˜ (Shared Memory)                              â”‚
â”‚  - å»¶è¿Ÿ: ~20 å‘¨æœŸ                                      â”‚
â”‚  - å®¹é‡: 48-96 KB/SM                                   â”‚
â”‚  - ä¼˜åŒ–: Padding é¿å… Bank Conflict                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ â‘¡ Thread åŠ è½½ Fragment
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å¯„å­˜å™¨ (Registers)                                    â”‚
â”‚  - å»¶è¿Ÿ: 1 å‘¨æœŸ                                        â”‚
â”‚  - å®¹é‡: 64 KB/SM, 255 ä¸ª/çº¿ç¨‹                         â”‚
â”‚  - å­˜å‚¨: res_reg[8Ã—8], frag_a[8], frag_b[8]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä¸ PyTorch æºç çš„å¯¹åº”å…³ç³»

è™½ç„¶æˆ‘ä»¬æ²¡æœ‰ç›´æ¥ä¿®æ”¹ PyTorch æºç ï¼Œä½†å®ç°çš„ç®—å­å¯¹åº” PyTorch ä¸­çš„ä»¥ä¸‹ä½ç½®ï¼š

| æˆ‘ä»¬çš„å®ç° | PyTorch å¯¹åº”ä½ç½® | è¯´æ˜ |
|-----------|-----------------|------|
| `gemm_kernel_optimized` | `aten/src/ATen/native/cuda/Blas.cpp` | GEMM è°ƒç”¨æ¥å£ |
| `postprocess_bias_add_layernorm` | `aten/src/ATen/native/cuda/layer_norm_kernel.cu` | LayerNorm Kernel |
| `gelu_activation` | `aten/src/ATen/native/cuda/ActivationGeluKernel.cu` | GELU æ¿€æ´» |

**æ³¨æ„ï¼š** æˆ‘ä»¬çš„å®ç°æ˜¯ç‹¬ç«‹çš„ C++/CUDA æ‰©å±•ï¼Œé€šè¿‡ `pybind11` æš´éœ²ç»™ Pythonï¼Œè€Œéä¿®æ”¹ PyTorch æºç ã€‚

---

## â“ å¸¸è§é—®é¢˜

### Q1: ç¼–è¯‘å¤±è´¥ï¼Œæç¤ºæ‰¾ä¸åˆ° CUDA

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æ£€æŸ¥ CUDA å®‰è£…
nvcc --version

# å¦‚æœæœªå®‰è£…ï¼Œå®‰è£… CUDA Toolkit 11.8
# Ubuntu:
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sudo sh cuda_11.8.0_520.61.05_linux.run

# è®¾ç½®ç¯å¢ƒå˜é‡
export CUDA_HOME=/usr/local/cuda-11.8
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
```

### Q2: è¿è¡Œæ—¶æç¤º `ImportError: cannot import name 'gemm_bias_add_layernorm'`

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# ç¡®ä¿è®¾ç½®äº†æ­£ç¡®çš„åº“è·¯å¾„
export LD_LIBRARY_PATH=$(python -c 'import torch,os;print(os.path.join(os.path.dirname(torch.__file__),"lib"))'):$LD_LIBRARY_PATH

# é‡æ–°ç¼–è¯‘
cd custom_ops
pip install -e . --no-build-isolation --force-reinstall
```

### Q3: PyTorch ç‰ˆæœ¬ä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# å¸è½½æ—§ç‰ˆæœ¬
pip uninstall torch torchvision torchaudio

# å®‰è£…æŒ‡å®šç‰ˆæœ¬ 2.1.0
pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118
```

### Q4: æµ‹è¯•æ•°æ®é›†ä¸‹è½½å¤±è´¥

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# ä½¿ç”¨ HuggingFace é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com

# æ‰‹åŠ¨ä¸‹è½½å¹¶ä¿å­˜æ•°æ®é›†
python << EOF
from datasets import load_dataset
dataset = load_dataset("imdb")
dataset.save_to_disk("./dataset/imdb")
EOF
```

### Q5: ä¸ºä»€ä¹ˆèåˆç®—å­æ€§èƒ½æ²¡æœ‰æ˜¾è‘—æå‡ï¼Ÿ

**å›ç­”ï¼š**
1. **GEMM å·²æ¥è¿‘å³°å€¼**ï¼šPyTorch ä½¿ç”¨ cuBLASï¼Œå·²è¾¾åˆ°ç¡¬ä»¶ 95% æ€§èƒ½
2. **æµ‹è¯•åœºæ™¯é™åˆ¶**ï¼šå•ç®—å­æµ‹è¯•æ— æ³•ä½“ç°ç«¯åˆ°ç«¯ä¼˜åŠ¿
3. **ä¼˜åŒ–ç©ºé—´æœ‰é™**ï¼šåå¤„ç†ï¼ˆLayerNorm ç­‰ï¼‰ä»…å  15-20% æ—¶é—´

**çœŸæ­£ä»·å€¼ï¼š**
- å‡å°‘å†…å­˜è®¿é—®ï¼ˆç†è®ºä¼˜åŒ– 50-60%ï¼‰
- é™ä½å»¶è¿Ÿæ³¢åŠ¨ï¼ˆå‡å°‘ Kernel å¯åŠ¨å¼€é”€ï¼‰
- ä¸ºè¿›ä¸€æ­¥ä¼˜åŒ–ï¼ˆTensor Coreã€INT8ï¼‰å¥ å®šåŸºç¡€

### Q6: å¦‚ä½•åœ¨è‡ªå·±çš„æ¨¡å‹ä¸­ä½¿ç”¨èåˆç®—å­ï¼Ÿ

**ç¤ºä¾‹ä»£ç ï¼š**
```python
import torch
from custom_ops_cuda import gemm_bias_add_layernorm, gemm_bias_gelu_add_layernorm

# æ›¿æ¢ Attention è¾“å‡ºå±‚
class OptimizedAttentionOutput(torch.nn.Module):
    def forward(self, hidden_states, input_tensor):
        # åŸç”Ÿå®ç°:
        # hidden_states = self.dense(hidden_states)
        # hidden_states = self.dropout(hidden_states)
        # hidden_states = self.LayerNorm(hidden_states + input_tensor)
        
        # èåˆå®ç°:
        hidden_states = gemm_bias_add_layernorm(
            hidden_states,                    # è¾“å…¥
            self.dense.weight.t().contiguous(),  # æƒé‡ï¼ˆè½¬ç½®ï¼‰
            self.dense.bias,                  # Bias
            input_tensor,                     # æ®‹å·®
            self.LayerNorm.weight,           # Gamma
            self.LayerNorm.bias,             # Beta
            1e-12                            # Epsilon
        )
        return self.dropout(hidden_states)
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### å­¦æœ¯è®ºæ–‡

1. **FasterTransformer**: [NVIDIA/FasterTransformer](https://github.com/NVIDIA/FasterTransformer)
2. **FlashAttention**: Dao et al. "FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness" (NeurIPS 2022)
3. **DeepSpeed Inference**: He et al. "DeepSpeed Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale" (SC 2022)

### CUDA ç¼–ç¨‹

1. [CUDA C++ Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/)
2. [CUTLASS: CUDA Templates for Linear Algebra Subroutines](https://github.com/NVIDIA/cutlass)
3. [How to Optimize GEMM](https://siboehm.com/articles/22/CUDA-MMM)

### PyTorch æ‰©å±•

1. [Custom C++ and CUDA Extensions](https://pytorch.org/tutorials/advanced/cpp_extension.html)
2. [PyTorch Profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)

---

## ğŸ“ License

MIT License

---

## ğŸ‘¥ ä½œè€…

- **é¡¹ç›®ç»´æŠ¤è€…**: lhl
- **æŠ€æœ¯æ”¯æŒ**: BERT æ¨ç†åŠ é€Ÿå°ç»„

---

## ğŸ™ è‡´è°¢

- PyTorch å›¢é˜Ÿæä¾›çš„æ·±åº¦å­¦ä¹ æ¡†æ¶
- NVIDIA æä¾›çš„ CUDA å·¥å…·é“¾å’Œä¼˜åŒ–æŒ‡å—
- HuggingFace æä¾›çš„ Transformers åº“å’Œæ•°æ®é›†

---

**æœ€åæ›´æ–°**: 2026-01-14
