# CS4302 PyTorch CUDA算子优化大作业 - 实验计划

## 环境信息
- **Python版本**: 3.13.9
- **CUDA版本**: 12.4
- **GCC版本**: 11.4.0
- **PyTorch源码目录**: `/home/honglianglu/hdd/CS4302-pytorch`
- **工作目录**: `/home/honglianglu/hdd/CS4302-pytorch/lab1_workspace`

## 实验步骤规划

### 第一阶段：环境准备与模型选择（第1-2周）

#### 1.1 确认PyTorch源码编译状态
- [ ] 检查PyTorch是否已从源码编译安装
- [ ] 验证CUDA支持是否正常
- [ ] 测试基本的CUDA操作

#### 1.2 选择神经网络模型
推荐选择 **YOLOv5** 或 **Transformers (BERT)**，理由：
- **YOLOv5**: 
  - 包含大量卷积操作（conv2d是核心算子）
  - 推理速度要求高，优化空间大
  - 易于部署和测试
  
- **Transformers (BERT)**:
  - 包含大量矩阵乘法（GEMM）和LayerNorm
  - Attention机制的优化空间大
  - 实际应用广泛

**初步选择：YOLOv5**（因为作业要求包含slow_conv2d_cuda的改写）

### 第二阶段：CUDA算子调研（第3-5周）

#### 2.1 使用PyTorch Profiler分析模型
步骤：
1. 编写YOLOv5推理测试脚本
2. 使用`torch.profiler`记录kernel调用
3. 分析热点算子（按调用次数和耗时排序）
4. 生成Chrome trace可视化文件

#### 2.2 调研至少3个CUDA算子实现
基于YOLOv5的特点，重点调研：
1. **Convolution (slow_conv2d_cuda)** - 必选
   - 位置：`aten/src/ATen/native/cuda/NaiveDilatedConvolution.cu`
   - 分析：im2col + GEMM实现原理
   
2. **ReLU Activation**
   - 位置：`aten/src/ATen/native/cuda/ActivationReLUKernel.cu`
   - 分析：element-wise并行化策略
   
3. **MaxPooling**
   - 位置：`aten/src/ATen/native/cuda/MaxPooling.cu`
   - 分析：窗口滑动并行化

备选：
- BatchNorm
- Upsample/Interpolate
- Concat

#### 2.3 调研CUDA Runtime API调用
重点调研：
- **内存管理**: `cudaMalloc`, `cudaFree`, `cudaMemcpy`
- **Stream管理**: `cudaStreamCreate`, `cudaStreamSynchronize`
- **Kernel启动**: `<<<grid, block, shared_mem, stream>>>`
- **错误处理**: `cudaGetLastError`, `cudaDeviceSynchronize`

在PyTorch中的位置：
- `c10/cuda/CUDAStream.h`
- `c10/cuda/CUDAFunctions.h`
- `aten/src/ATen/cuda/CUDAContext.cpp`

### 第三阶段：算子优化实现（第6-10周）

#### 3.1 slow_conv2d_cuda优化（必做）
优化方向：
1. **Shared Memory优化**：减少全局内存访问
2. **Tile策略**：提高数据重用
3. **Memory Coalescing**：优化内存访问模式
4. **向量化加载**：使用float4等向量类型
5. **循环展开**：减少控制流开销

实现步骤：
```
1. 复制原始实现到lab1_workspace
2. 创建优化版本：conv2d_optimized.cu
3. 修改native_functions.yaml注册
4. 重新编译PyTorch
5. 测试正确性和性能
```

#### 3.2 其他算子优化（可选但推荐）
- ReLU融合优化（Conv+ReLU融合）
- MaxPooling优化

#### 3.3 实现文件组织
```
lab1_workspace/
├── src/
│   ├── conv2d_optimized.cu          # 优化的卷积实现
│   ├── conv2d_optimized.h           # 头文件
│   └── cuda_utils.cuh               # 通用CUDA工具
├── benchmark/
│   ├── profile_yolov5.py           # YOLOv5性能测试
│   ├── test_correctness.py         # 正确性验证
│   └── compare_performance.py      # 性能对比
├── docs/
│   ├── 算子调研报告.md
│   └── 优化方法说明.md
└── README.md
```

### 第四阶段：测试与性能对比（第11-13周）

#### 4.1 正确性测试
- 单元测试：对比原始实现和优化实现的输出
- 端到端测试：在YOLOv5上验证精度

#### 4.2 性能测试
对比维度：
- 不同输入尺寸（224x224, 416x416, 640x640）
- 不同batch size（1, 4, 8, 16）
- 不同channel配置
- 不同kernel size

测量指标：
- 单算子耗时（microseconds）
- 端到端推理时间（ms）
- GPU利用率
- 内存带宽利用率

工具：
- `torch.profiler`
- `nvprof` / `nsys`
- `nvidia-smi`

### 第五阶段：报告撰写（第14-15周）

#### 5.1 实验报告结构
```
1. 摘要与分工
2. 环境配置
3. CUDA算子调研
   3.1 算子profiling结果
   3.2 三个算子的原理分析
   3.3 CUDA Runtime API调研
4. 算子优化实现
   4.1 slow_conv2d_cuda优化方法
   4.2 代码实现详解
   4.3 优化技术说明
5. 实验结果
   5.1 正确性验证
   5.2 性能对比数据
   5.3 性能分析与讨论
6. 结论与心得
```

#### 5.2 代码提交清单
- [ ] README.md（包含PyTorch版本和文件路径）
- [ ] 优化后的源代码文件
- [ ] 测试脚本
- [ ] 性能测试结果截图
- [ ] 实验报告PDF

### 第六阶段：答辩准备（第16周）

#### 6.1 中期答辩（第12周）
展示内容：
- 算子调研结果
- 优化方案设计
- 初步实现进展

#### 6.2 最终答辩（第16周）
展示内容：
- 完整的优化实现
- 性能对比结果
- 优化效果分析
- Demo演示

## 关键技术点

### Conv2d CUDA优化技术
1. **Im2col + GEMM方法**
2. **Winograd卷积**（可选高级优化）
3. **Direct Convolution with Shared Memory**
4. **Tensor Core利用**（如果硬件支持）

### 性能优化checklist
- [ ] 消除Bank Conflict
- [ ] 优化Global Memory访问（Coalescing）
- [ ] 使用Shared Memory
- [ ] 循环展开
- [ ] 向量化内存访问
- [ ] 减少分支divergence
- [ ] 合理的Grid/Block配置
- [ ] 使用Constant Memory（卷积核）
- [ ] Stream并行（可选）

## 参考资源
1. PyTorch官方文档：https://pytorch.org/docs/stable/index.html
2. CUDA C++ Programming Guide
3. NVIDIA CUDA Best Practices Guide
4. cuDNN Documentation（参考但不直接使用）
5. Papers:
   - "Fast Algorithms for Convolutional Neural Networks" (Winograd)
   - "Optimizing CUDA-based GPU Kernels for Deep Learning"

## 时间线
- Week 1-2: 环境准备，模型选择
- Week 3-5: 算子调研和分析
- Week 6-10: 算子优化实现
- Week 11-13: 测试和性能对比
- Week 12: 中期答辩
- Week 14-15: 报告撰写
- Week 16: 最终答辩

## 评分对应工作
1. **算子调研(30%)**: 
   - Profiler分析报告
   - 3个算子的详细分析
   - CUDA Runtime API调研
   
2. **算子实现正确性(25%)**:
   - 单元测试通过
   - 端到端精度验证
   
3. **优化效果(15%)**:
   - 性能提升数据
   - 对比基线的加速比
   
4. **文档代码展示(30%)**:
   - 完整的实验报告
   - 清晰的代码注释
   - 可复现的README
   - 答辩质量



